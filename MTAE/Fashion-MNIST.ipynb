{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import pickle , gzip\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "device='cuda:0'\n",
    "\n",
    "seed = 999\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_CLOTHING = {0 :'T-shirt-top',\n",
    "                  1 :'Trouser',\n",
    "                  2 :'Pullover',\n",
    "                  3 :'Dress',\n",
    "                  4 :'Coat',\n",
    "                  5 :'Sandal',\n",
    "                  6 :'Shirt',\n",
    "                  7 :'Sneaker',\n",
    "                  8 :'Bag',\n",
    "                  9 :'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rotated_fmnist(left_out_idx=0):\n",
    "    train_x = []\n",
    "    test_x = []\n",
    "    train_y = []\n",
    "    test_y = []\n",
    "\n",
    "    random = []\n",
    "    for i in range(10):\n",
    "        random.append(np.random.permutation(6000))\n",
    "    \n",
    "    for i in range(6):\n",
    "        angle = 360- 15*i\n",
    "        transform = transforms.Compose([transforms.RandomRotation(degrees = (angle,angle)),transforms.ToTensor()])\n",
    "        cifar_train = datasets.FashionMNIST(root='data/',download=False, train=True, transform=transform)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=cifar_train, batch_size=60000,shuffle=False)\n",
    "\n",
    "        dataset = next(iter(train_loader))\n",
    "        \n",
    "        targets = dataset[1]\n",
    "          \n",
    "        data = dataset[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        \n",
    "        #Picks 1000 images from each class\n",
    "        for j in range(10):\n",
    "           \n",
    "            idx = targets==j\n",
    "            jth_target = targets[idx]\n",
    "            jth_data = data[idx]\n",
    "            jth_data = jth_data[random[j]]\n",
    "            \n",
    "            \n",
    "            sample_x = jth_data[:1000]\n",
    "            sample_y = jth_target[:1000]\n",
    "            \n",
    "            data_x.append(sample_x)\n",
    "            data_y.append(sample_y.float())\n",
    "        \n",
    "        data_x  = torch.cat(data_x).to(device)\n",
    "\n",
    "        data_y  = torch.cat(data_y).to(device)\n",
    "\n",
    "        \n",
    "        if i!=left_out_idx:\n",
    "            train_x.append(data_x)\n",
    "            train_y.append(data_y)\n",
    "        else:\n",
    "            test_x = data_x\n",
    "            test_y = data_y\n",
    "    \n",
    "    return train_x,train_y,test_x,test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MTAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "     \n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 500,bias=True).to(device),\n",
    "            nn.ReLU(),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x).to(device)\n",
    "       \n",
    "        return out\n",
    "\n",
    "      \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "     \n",
    "        self.decoder  = nn.Sequential(\n",
    "                nn.Linear(500, 28*28,bias=True).to(device),\n",
    "            \n",
    "                nn.ReLU(),\n",
    "            \n",
    "            ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.decoder(x).to(device)   \n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class MTAE:\n",
    "    def __init__(self):\n",
    "        super(MTAE,self).__init__()\n",
    "          \n",
    "        learning_rate = 0.007\n",
    "        weight_decay = 3e-4\n",
    "\n",
    "        self.Encoder = Encoder().to(device)\n",
    "\n",
    "        self.Decoder = Decoder().to(device)\n",
    "\n",
    "        self.params = list(self.Encoder.parameters()) + list(self.Decoder.parameters())\n",
    "\n",
    "        self.optimizer = torch.optim.Adamax(params=self.params, lr=learning_rate,weight_decay=weight_decay)\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "            \n",
    "        \n",
    "    def train(self,X,Y,domainId):\n",
    "  \n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        out = self.Encoder(X)\n",
    "        \n",
    "        out = self.Decoder(out)\n",
    "                \n",
    "        cost = self.criterion(out, Y)\n",
    "\n",
    "        cost.backward()\n",
    "  \n",
    "        self.optimizer.step()\n",
    "                \n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        return cost.data.item()\n",
    "    \n",
    "    def get_features(self,X):\n",
    "        model = self.Encoder\n",
    "        model = model.eval()\n",
    "\n",
    "        out = model(X)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(512, 64).to(device)\n",
    "        self.fc2 = nn.Linear(64, 10).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x)).to(device)\n",
    "        x = F.relu(self.fc2(x)).to(device)\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "def Neuron(feat_train, y_train,feat_test,y_test):\n",
    "    model = NeuralNet().to(device)\n",
    "\n",
    "    learning_rate = 0.002\n",
    "    weight_decay = 0.001\n",
    "\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate,weight_decay=weight_decay)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch_size = 40\n",
    "\n",
    "    training_epochs = 70\n",
    "\n",
    "    train_tensor = torch.utils.data.TensorDataset(feat_train, y_train) \n",
    "    train_loader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    total_batch = 50000 // batch_size\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        for i, (X, Y) in enumerate(train_loader):\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            hypothesis = model(X)\n",
    "\n",
    "            Y= Y.view(Y.shape[0])\n",
    "\n",
    "            Y= Y.long()\n",
    "            cost = criterion(hypothesis, Y)\n",
    "\n",
    "            cost.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            avg_cost += (cost.data / total_batch)\n",
    "\n",
    "        if epoch%10==0:\n",
    "            print(\"Epoch: {}, averaged cost = {:.4f}\".format(epoch + 1, avg_cost.item()))\n",
    "\n",
    "\n",
    "    print('Learning Finished!')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        out = model(feat_test)\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        \n",
    "        y_test = y_test.long()\n",
    "        correct += (predicted == y_test).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / len(y_test)))\n",
    "        accuracy =correct/len(y_test)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linear_svm(feat_train,y_train,feat_test,y_test):#training_data,test_data):\n",
    "  \n",
    "    x = np.array(feat_train)\n",
    "    y = np.array(y_train)\n",
    "\n",
    "    linear_svm = OneVsRestClassifier(LinearSVC(C=3, max_iter=10000), n_jobs=-1)\n",
    "\n",
    "    linear_svm.fit(x,y)\n",
    "\n",
    "\n",
    "    train_outcome = linear_svm.predict(x)\n",
    "    \n",
    "    \n",
    "    train_result = (train_outcome == y).sum()\n",
    "    \n",
    "\n",
    "    train_accuracy = train_result/len(x)\n",
    "    \n",
    "    print(\"Training Accuracy: %.8f\" % train_accuracy)\n",
    "    train_error = 1-train_accuracy\n",
    "    print(\"Training Error: %.8f\" % train_error)\n",
    "\n",
    "    outcome = linear_svm.predict(np.array(feat_test))\n",
    "    \n",
    "\n",
    "    result = (outcome == y_test).sum()\n",
    "\n",
    "    accuracy = result/len(outcome)\n",
    "    print(\"Test accuracy: %.8f\" % accuracy)\n",
    "    test_error = 1-accuracy\n",
    "    print(\"Test Error: %.8f\" % test_error)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_training(dom):\n",
    "    train_x,train_y,test_x,test_y = load_rotated_fmnist(left_out_idx=dom)\n",
    "    batch_size=50\n",
    "    \n",
    "    mtae = MTAE()\n",
    "    \n",
    "    for epoch in range(10):\n",
    "\n",
    "      \n",
    "        x_train = []\n",
    "        y_train = []\n",
    "\n",
    "        random = np.random.permutation(10000)\n",
    "\n",
    "        for i in range(5):\n",
    "            x = train_x[i]\n",
    "            x_permuted = x[random]\n",
    "\n",
    "            y = train_y[i]\n",
    "            y_permuted = y[random]\n",
    "            \n",
    "            x_train.append(x_permuted)\n",
    "            y_train.append(y_permuted)\n",
    "            \n",
    "        \n",
    "        x_train = torch.cat(x_train).to(device)\n",
    "\n",
    "        x_train = x_train.view(5,10000,28*28)\n",
    "        \n",
    "        y_train  = torch.cat(y_train).to(device)\n",
    "        \n",
    "       \n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                avg_cost = 0\n",
    "                for k in range(0,10000,50):\n",
    "                    \n",
    "                    left_x = x_train[i][k:k+50,:]\n",
    "                    \n",
    "                    right_x = x_train[j][k:k+50,:]\n",
    "                    \n",
    "                    avg_cost+= mtae.train(left_x,right_x,i)\n",
    "                \n",
    "                avg_cost = avg_cost/200\n",
    "                \n",
    "#             print(avg_cost)\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "    \n",
    "    x_train = x_train.view(50000,28*28)\n",
    "    \n",
    "    train_feat = mtae.get_features(x_train)\n",
    "\n",
    "    train_feat = train_feat.detach()\n",
    "\n",
    "    feat_train = train_feat.view((50000,500))\n",
    "\n",
    "    \n",
    "    y_train = y_train.view(50000,1)\n",
    "    \n",
    "    x_test = test_x.view((10000, 28*28))\n",
    "\n",
    "    feat = mtae.get_features(x_test)\n",
    "    \n",
    "    feat  = feat.detach()\n",
    "\n",
    "    feat_test = feat.view((10000, 500))\n",
    "\n",
    "\n",
    "    y_test = test_y.view(10000)\n",
    "\n",
    "    y_test = y_test.long()\n",
    "\n",
    "    print('-------------------------')\n",
    "\n",
    "\n",
    "    linear_svm(feat_train.cpu(),y_train.cpu(),feat_test.cpu(),y_test.cpu())\n",
    "#     accuracy= Neuron(feat_train.detach(),y_train.detach(),feat_test.detach(),y_test.detach())\n",
    "\n",
    "    print(\"Accuracy :\", accuracy/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dom in range(1,6):\n",
    "    print(\"----------------------Domain.{}---------------------\".format(dom))\n",
    "    leave_one_out_training(dom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
